# ğŸ“Š Progresso do Tech Challenge - LSTM Stock Predictor

Este arquivo rastreia o progresso do projeto em relaÃ§Ã£o ao guia:
**`docs - fase 4 /tech challenge/Guia de PrediÃ§Ã£o de AÃ§Ãµes com LSTM- Tech Challenge 4`**

---

## ğŸ—ºï¸ Mapa Geral do Projeto

```text
[âœ…] ETAPA 1: Setup do Ambiente          â” CONCLUÃDA (2026-02-17)
[âœ…] ETAPA 2: Coleta de Dados (yfinance)  â” CONCLUÃDA (2026-02-17)
[âœ…] ETAPA 3: PrÃ©-processamento           â” CONCLUÃDA (2026-02-17)
[âœ…] ETAPA 4: Modelo LSTM                 â” CONCLUÃDA (2026-02-17)
[âœ…] ETAPA 5: Treinamento                 â” CONCLUÃDA (2026-02-17)
[ ] ETAPA 6: AvaliaÃ§Ã£o                   â” Pendente
[ ] ETAPA 7: Salvamento                  â” Pendente
[ ] ETAPA 8: API FastAPI                 â” Pendente
[ ] ETAPA 9: Docker e Monitoramento      â” Pendente
```

---

## âœ… ETAPA 1: ConfiguraÃ§Ã£o do Ambiente

**ğŸ“… Data de ConclusÃ£o:** 2026-02-17  
**â±ï¸ Tempo Estimado:** 30 min | **Tempo Real:** ~15 min

### O que foi feito:

1. **Estrutura de pastas criada** (conforme `setup_github_projeto.md` linhas 18-34)
   ```
   tech-challenge-lstm/
   â”œâ”€â”€ README.md              âœ…
   â”œâ”€â”€ requirements.txt       âœ…
   â”œâ”€â”€ .gitignore             âœ…
   â”œâ”€â”€ Dockerfile             âœ…
   â”œâ”€â”€ src/                   âœ…
   â”‚   â”œâ”€â”€ data_collection.py âœ… (implementado)
   â”‚   â”œâ”€â”€ preprocessing.py   âœ… (implementado)
   â”‚   â”œâ”€â”€ model.py           âœ… (implementado)
   â”‚   â”œâ”€â”€ train.py           âœ… (implementado)
   â”‚   â”œâ”€â”€ evaluate.py        âœ… (pendente)
   â”‚   â””â”€â”€ app.py             âœ… (pendente)
   â”œâ”€â”€ models/                âœ…
   â”œâ”€â”€ data/                  âœ…
   â”œâ”€â”€ notebooks/             âœ…
   â””â”€â”€ docs - fase 4 /        âœ… (contexto)
   ```

2. **Ambiente virtual criado e ativado**
   ```bash
   python -m venv venv
   source venv/bin/activate
   ```

3. **DependÃªncias instaladas** (Guia linhas 71-81)
   
   | Pacote | VersÃ£o Instalada | Status |
   |--------|------------------|--------|
   | yfinance | 1.2.0 | âœ… |
   | pandas | 3.0.0 | âœ… |
   | numpy | 2.4.2 | âœ… |
   | torch | 2.10.0 | âœ… |
   | scikit-learn | 1.8.0 | âœ… |
   | fastapi | 0.129.0 | âœ… |
   | uvicorn | 0.41.0 | âœ… |
   | matplotlib | 3.10.8 | âœ… |
   | joblib | 1.5.3 | âœ… |

4. **VerificaÃ§Ã£o do ambiente**
   ```bash
   python -c "import yfinance, pandas, numpy, torch, sklearn, fastapi; print('Ambiente OK!')"
   # Resultado: âœ… Ambiente OK!
   ```

### Arquivos criados/modificados:
- `requirements.txt` - Lista de dependÃªncias
- `.gitignore` - Arquivos a ignorar no Git
- `Dockerfile` - ConfiguraÃ§Ã£o para containerizaÃ§Ã£o
- `README.md` - DescriÃ§Ã£o do projeto
- `venv/` - Ambiente virtual Python

---

## âœ… ETAPA 2: Coleta de Dados (yfinance)

**ğŸ“… Data de ConclusÃ£o:** 2026-02-17  
**â±ï¸ Tempo Estimado:** 30 min | **Tempo Real:** ~10 min

### O que foi feito:

1. **Implementado `src/data_collection.py`** com:
   - FunÃ§Ã£o `download_stock_data()` para baixar dados do yfinance
   - FunÃ§Ã£o `load_stock_data()` para carregar dados salvos
   - ConfiguraÃ§Ãµes flexÃ­veis (ticker, perÃ­odo)
   - Salvamento automÃ¡tico em CSV

2. **ConfiguraÃ§Ãµes escolhidas:**
   - **Ticker:** `PETR4.SA` (Petrobras)
   - **PerÃ­odo:** 2018-01-01 atÃ© 2024-01-01
   - **Dados obtidos:** 1487 registros

3. **EstatÃ­sticas dos dados:**
   ```
   Shape: (1487, 5)
   PerÃ­odo real: 2018-01-02 atÃ© 2023-12-28
   PreÃ§o mÃ­nimo:  R$ 3.24
   PreÃ§o mÃ¡ximo:  R$ 27.38
   PreÃ§o mÃ©dio:   R$ 10.17
   ```

4. **Arquivo gerado:**
   - `data/data_PETR4_SA.csv` - Dados histÃ³ricos salvos

### Arquivos criados/modificados:
- `src/data_collection.py` - Script de coleta de dados
- `data/data_PETR4_SA.csv` - Dados baixados

### ğŸ‰ Checkpoint: "Dados na mÃ£o!" âœ…

---

## âœ… ETAPA 3: PrÃ©-processamento

**ğŸ“… Data de ConclusÃ£o:** 2026-02-17  
**â±ï¸ Tempo Estimado:** 45 min | **Tempo Real:** ~10 min

### O que foi feito:

1. **Implementado `src/preprocessing.py`** com funÃ§Ãµes:
   - `normalize_data()` - Normaliza com MinMaxScaler (0-1)
   - `create_sequences()` - Cria janelas deslizantes
   - `train_test_split()` - Divide treino/teste
   - `to_tensors()` - Converte para tensores PyTorch
   - `preprocess_data()` - Pipeline completa

2. **ParÃ¢metros configurados:**
   - **SEQ_LENGTH:** 60 dias (~3 meses)
   - **TRAIN_SPLIT:** 80% treino / 20% teste

3. **Resultado do prÃ©-processamento:**
   ```
   Dados originais:  1487 registros
   ApÃ³s sequÃªncias:  1427 amostras
   
   X_train: (1141, 60, 1) - 1141 amostras de treino
   y_train: (1141, 1)
   X_test:  (286, 60, 1)  - 286 amostras de teste
   y_test:  (286, 1)
   ```

4. **Artefatos salvos em `models/`:**
   - `scaler.pkl` - Scaler para reverter normalizaÃ§Ã£o
   - `config.pkl` - ConfiguraÃ§Ãµes (seq_length, ticker, etc.)

### Arquivos criados/modificados:
- `src/preprocessing.py` - Script de prÃ©-processamento
- `models/scaler.pkl` - Scaler serializado
- `models/config.pkl` - ConfiguraÃ§Ãµes do modelo

### ğŸ‰ Checkpoint: "Dados prontos!" âœ…

---

## âœ… ETAPA 4: Modelo LSTM

**ğŸ“… Data de ConclusÃ£o:** 2026-02-17  
**â±ï¸ Tempo Estimado:** 45 min | **Tempo Real:** ~10 min

### O que foi feito:

1. **Implementado `src/model.py`** com:
   - Classe `StockLSTM` herdando de `nn.Module`
   - FunÃ§Ã£o `create_model()` para instanciar
   - FunÃ§Ã£o `count_parameters()` para debug

2. **Arquitetura definida:**
   ```
   StockLSTM(
     (lstm): LSTM(1, 50, num_layers=2, batch_first=True, dropout=0.2)
     (dropout): Dropout(p=0.2)
     (linear): Linear(in_features=50, out_features=1)
   )
   ```

3. **HiperparÃ¢metros configurados:**
   - `input_size`: 1 (apenas preÃ§o Close)
   - `hidden_size`: 50 (dimensÃ£o do estado oculto)
   - `num_layers`: 2 (LSTM empilhadas)
   - `dropout`: 0.2 (20% regularizaÃ§Ã£o)

4. **EstatÃ­sticas do modelo:**
   - **ParÃ¢metros treinÃ¡veis:** 31,051
   - **Dispositivo:** CPU (GPU se disponÃ­vel)

### Arquivos criados/modificados:
- `src/model.py` - DefiniÃ§Ã£o da arquitetura LSTM

### ğŸ‰ Checkpoint: "O cÃ©rebro nasceu!" âœ…

---

## âœ… ETAPA 5: Treinamento

**ğŸ“… Data de ConclusÃ£o:** 2026-02-17  
**â±ï¸ Tempo Estimado:** 1h+ | **Tempo Real:** ~20 min (19s treino)

### O que foi feito:

1. **Implementado `src/train.py`** com funÃ§Ãµes:
   - `train_model()` - Loop de treinamento completo
   - `plot_training_history()` - VisualizaÃ§Ã£o de perdas
   - `save_trained_model()` - Salva modelo treinado

2. **ConfiguraÃ§Ã£o do treinamento:**
   - **Dispositivo:** CPU
   - **Ã‰pocas:** 100
   - **Learning Rate:** 0.001
   - **Loss Function:** MSELoss
   - **Otimizador:** Adam

3. **Resultados do treinamento:**
   ```
   Tempo total:       18.7s (0.19s/Ã©poca)
   Train Loss final:  0.001405
   Val Loss final:    0.002383
   Melhor Val Loss:   0.001508 (Ã©poca 97)
   ```

4. **Artefatos gerados:**
   - `models/model_lstm.pth` - Modelo treinado
   - `models/training_history.png` - GrÃ¡fico de perdas

### Arquivos criados/modificados:
- `src/train.py` - Script de treinamento
- `models/model_lstm.pth` - Modelo serializado
- `models/training_history.png` - VisualizaÃ§Ã£o

### ğŸ‰ Checkpoint: "Modelo treinado!" âœ…

---

## ğŸ”œ ETAPA 6: AvaliaÃ§Ã£o

**ğŸ“… Status:** â³ PENDENTE

### Objetivos:
- [ ] Calcular MAE (Erro MÃ©dio Absoluto)
- [ ] Calcular RMSE (Raiz do Erro QuadrÃ¡tico MÃ©dio)
- [ ] Calcular MAPE (Erro Percentual MÃ©dio)
- [ ] Gerar grÃ¡fico de previsÃµes vs valores reais

### Arquivo a implementar:
- `src/evaluate.py`

---

## ğŸ”œ ETAPA 7: Salvamento

**ğŸ“… Status:** â³ PENDENTE

### Objetivos:
- [ ] Salvar modelo treinado (`model_lstm.pth`)
- [ ] Salvar scaler (`scaler.pkl`)
- [ ] Salvar configuraÃ§Ãµes (`config.pkl`)

### Arquivos a gerar:
- `models/model_lstm.pth`
- `models/scaler.pkl`
- `models/config.pkl`

---

## ğŸ”œ ETAPA 8: API FastAPI

**ğŸ“… Status:** â³ PENDENTE

### Objetivos:
- [ ] Criar endpoint `/predict`
- [ ] Criar endpoint `/health`
- [ ] Carregar modelo no startup
- [ ] Validar entrada e retornar previsÃ£o

### Arquivo a implementar:
- `src/app.py`

---

## ğŸ”œ ETAPA 9: Docker e Monitoramento

**ğŸ“… Status:** â³ PENDENTE (parcial)

### Objetivos:
- [x] Criar Dockerfile (jÃ¡ existe estrutura base)
- [ ] Criar docker-compose.yml (opcional)
- [ ] Testar build e execuÃ§Ã£o do container
- [ ] Configurar healthcheck

---

## ğŸ“‹ Checklist de Entrega Final

- [x] CÃ³digo-fonte no repositÃ³rio Git
- [x] requirements.txt com versÃµes
- [ ] README.md documentando o projeto (expandir)
- [ ] Modelo treinado (.pth) e scaler (.pkl)
- [x] Dockerfile funcional (estrutura base)
- [ ] MÃ©tricas de avaliaÃ§Ã£o calculadas
- [ ] VÃ­deo demonstrando a API funcionando

---

## ğŸ“ Notas e ObservaÃ§Ãµes

### DecisÃµes tomadas:
- **Ticker escolhido:** `PETR4.SA` (Petrobras - aÃ§Ã£o brasileira)
- **PerÃ­odo de dados:** 2018-01-01 atÃ© 2024-01-01
- **SEQ_LENGTH:** 60 dias (recomendado no guia)
- **Split treino/teste:** 80%/20%

### Problemas encontrados:
- Nenhum atÃ© o momento

---

*Ãšltima atualizaÃ§Ã£o: 2026-02-17*
