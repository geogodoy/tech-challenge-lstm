# Guia Passo a Passo: Treinamento e AvaliaÃ§Ã£o do Modelo LSTM

> Guia prÃ¡tico e didÃ¡tico para treinar e avaliar o modelo de previsÃ£o de preÃ§os de aÃ§Ãµes

---

## Ãndice

1. [VisÃ£o Geral do Processo](#1-visÃ£o-geral-do-processo)
2. [PrÃ©-requisitos](#2-prÃ©-requisitos)
3. [Parte 1: Treinamento do Modelo](#parte-1-treinamento-do-modelo)
   - [Passo 1: Carregar os Dados](#passo-1-carregar-os-dados)
   - [Passo 2: Criar o Modelo](#passo-2-criar-o-modelo)
   - [Passo 3: Configurar HiperparÃ¢metros](#passo-3-configurar-hiperparÃ¢metros)
   - [Passo 4: Executar o Treinamento](#passo-4-executar-o-treinamento)
   - [Passo 5: Monitorar o Progresso](#passo-5-monitorar-o-progresso)
   - [Passo 6: Salvar o Modelo](#passo-6-salvar-o-modelo)
4. [Parte 2: AvaliaÃ§Ã£o do Modelo](#parte-2-avaliaÃ§Ã£o-do-modelo)
   - [Passo 7: Carregar o Modelo Salvo](#passo-7-carregar-o-modelo-salvo)
   - [Passo 8: Fazer PrevisÃµes](#passo-8-fazer-previsÃµes)
   - [Passo 9: Calcular MÃ©tricas](#passo-9-calcular-mÃ©tricas)
   - [Passo 10: Interpretar Resultados](#passo-10-interpretar-resultados)
5. [DiagnÃ³stico e Ajustes](#5-diagnÃ³stico-e-ajustes)
6. [Checklist Final](#6-checklist-final)
7. [GlossÃ¡rio](#7-glossÃ¡rio)

---

## 1. VisÃ£o Geral do Processo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUXO COMPLETO                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TREINAMENTO                         AVALIAÃ‡ÃƒO                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚                                                                 â”‚
â”‚  1. Carregar dados                   7. Carregar modelo         â”‚
â”‚         â†“                                   â†“                   â”‚
â”‚  2. Criar modelo                     8. Fazer previsÃµes         â”‚
â”‚         â†“                                   â†“                   â”‚
â”‚  3. Configurar hiperparÃ¢metros       9. Calcular mÃ©tricas       â”‚
â”‚         â†“                                   â†“                   â”‚
â”‚  4. Executar treinamento            10. Interpretar resultados  â”‚
â”‚         â†“                                   â†“                   â”‚
â”‚  5. Monitorar progresso                    â”‚                    â”‚
â”‚         â†“                                  â”‚                    â”‚
â”‚  6. Salvar modelo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### O que Ã© Treinamento?

Ã‰ o processo onde o modelo "aprende" padrÃµes nos dados. Funciona como ensinar uma crianÃ§a a jogar dardos:

1. **Joga** (forward pass) â†’ faz uma previsÃ£o
2. **VÃª o erro** (loss) â†’ mede a distÃ¢ncia do alvo
3. **Entende** (backward) â†’ descobre o que causou o erro
4. **Ajusta** (optimizer) â†’ corrige a mira
5. **Repete** â†’ atÃ© acertar consistentemente

### O que Ã© AvaliaÃ§Ã£o?

Ã‰ verificar se o modelo realmente aprendeu, testando com dados que ele **nunca viu** durante o treinamento.

---

## 2. PrÃ©-requisitos

### Arquivos necessÃ¡rios

```
tech-challenge-lstm/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_collection.py    âœ“ Coleta de dados
â”‚   â”œâ”€â”€ preprocessing.py      âœ“ PrÃ©-processamento
â”‚   â”œâ”€â”€ model.py              âœ“ Arquitetura LSTM
â”‚   â””â”€â”€ train.py              âœ“ FunÃ§Ã£o de treinamento
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data_PETR4_SA.csv     âœ“ Dados histÃ³ricos
â””â”€â”€ models/                    (serÃ¡ criado)
```

### Verificar se tudo estÃ¡ pronto

```python
# Execute no terminal ou em um script Python
from preprocessing import preprocess_data
from model import create_model

# Testar se os dados carregam
X_train, X_test, y_train, y_test, scaler = preprocess_data()
print(f"âœ… Dados carregados: {X_train.shape[0]} amostras de treino")

# Testar se o modelo cria
model = create_model()
print(f"âœ… Modelo criado: {sum(p.numel() for p in model.parameters())} parÃ¢metros")
```

---

# PARTE 1: TREINAMENTO DO MODELO

---

## Passo 1: Carregar os Dados

### O que fazer

```python
from preprocessing import preprocess_data

# Carregar dados prÃ©-processados
X_train, X_test, y_train, y_test, scaler = preprocess_data()
```

### O que vocÃª recebe

| VariÃ¡vel | Shape | O que Ã© |
|----------|-------|---------|
| `X_train` | (N, 60, 1) | SequÃªncias de 60 dias para treino |
| `X_test` | (M, 60, 1) | SequÃªncias de 60 dias para validaÃ§Ã£o |
| `y_train` | (N, 1) | PreÃ§o do dia 61 (treino) |
| `y_test` | (M, 1) | PreÃ§o do dia 61 (validaÃ§Ã£o) |
| `scaler` | MinMaxScaler | Para reverter normalizaÃ§Ã£o depois |

### Verificar os dados

```python
print(f"Amostras de treino: {X_train.shape[0]}")
print(f"Amostras de teste:  {X_test.shape[0]}")
print(f"Tamanho da sequÃªncia: {X_train.shape[1]} dias")
print(f"Features por dia: {X_train.shape[2]}")
```

**SaÃ­da esperada:**
```
Amostras de treino: 1131
Amostras de teste:  283
Tamanho da sequÃªncia: 60 dias
Features por dia: 1
```

### Por que esse passo Ã© importante?

- Os dados jÃ¡ estÃ£o **normalizados** (valores entre 0 e 1)
- JÃ¡ estÃ£o **divididos** em treino (80%) e teste (20%)
- JÃ¡ estÃ£o no **formato correto** para a LSTM (tensores PyTorch)

---

## Passo 2: Criar o Modelo

### O que fazer

```python
from model import create_model

# Criar modelo com configuraÃ§Ã£o padrÃ£o
model = create_model()

# Ou criar com configuraÃ§Ã£o personalizada
model = create_model(
    input_size=1,      # 1 feature (preÃ§o Close)
    hidden_size=50,    # 50 neurÃ´nios na camada oculta
    num_layers=2,      # 2 camadas LSTM empilhadas
    dropout=0.2        # 20% de dropout para regularizaÃ§Ã£o
)
```

### Verificar o modelo

```python
print(model)
print(f"\nTotal de parÃ¢metros: {sum(p.numel() for p in model.parameters()):,}")
```

**SaÃ­da esperada:**
```
StockLSTM(
  (lstm): LSTM(1, 50, num_layers=2, batch_first=True, dropout=0.2)
  (dropout): Dropout(p=0.2, inplace=False)
  (linear): Linear(in_features=50, out_features=1, bias=True)
)

Total de parÃ¢metros: 31,051
```

### Entendendo a arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARQUITETURA DO MODELO                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ENTRADA: 60 dias de preÃ§os normalizados                        â”‚
â”‚           shape: (batch, 60, 1)                                 â”‚
â”‚                      â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LSTM Camada 1: processa a sequÃªncia temporal           â”‚   â”‚
â”‚  â”‚  - Aprende padrÃµes de curto prazo                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LSTM Camada 2: refina os padrÃµes                       â”‚   â”‚
â”‚  â”‚  - Aprende padrÃµes mais abstratos                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Dropout (20%): regularizaÃ§Ã£o                           â”‚   â”‚
â”‚  â”‚  - Evita overfitting                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Linear: 50 â†’ 1 neurÃ´nio                                â”‚   â”‚
â”‚  â”‚  - Converte para preÃ§o Ãºnico                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â†“                                          â”‚
â”‚  SAÃDA: 1 preÃ§o previsto (normalizado)                         â”‚
â”‚         shape: (batch, 1)                                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Passo 3: Configurar HiperparÃ¢metros

### HiperparÃ¢metros principais

```python
# ConfiguraÃ§Ãµes de treinamento
EPOCHS = 100          # NÃºmero de passagens pelos dados
LEARNING_RATE = 0.001 # Velocidade de aprendizado
```

### Guia de escolha

| HiperparÃ¢metro | Valor PadrÃ£o | Quando Aumentar | Quando Diminuir |
|----------------|--------------|-----------------|-----------------|
| **EPOCHS** | 100 | Loss ainda caindo no final | Overfitting detectado |
| **LEARNING_RATE** | 0.001 | ConvergÃªncia muito lenta | Loss oscilando muito |
| **hidden_size** | 50 | Underfitting | Overfitting |
| **num_layers** | 2 | PadrÃµes muito complexos | Modelo muito lento |
| **dropout** | 0.2 | Overfitting | Underfitting |

### Tabela de referÃªncia para Learning Rate

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ESCALA DE LEARNING RATE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  0.1     â†’ Muito rÃ¡pido (instÃ¡vel, nÃ£o recomendado)          â”‚
â”‚  0.01    â†’ RÃ¡pido                                            â”‚
â”‚  0.001   â†’ Moderado (PADRÃƒO para Adam) â† RECOMENDADO         â”‚
â”‚  0.0001  â†’ Lento (para ajuste fino)                          â”‚
â”‚  0.00001 â†’ Muito lento                                       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Passo 4: Executar o Treinamento

### OpÃ§Ã£o A: Executar via script (mais simples)

```bash
cd tech-challenge-lstm
python src/train.py
```

### OpÃ§Ã£o B: Executar via cÃ³digo (mais controle)

```python
from train import train_model
from model import create_model
from preprocessing import preprocess_data

# 1. Carregar dados
X_train, X_test, y_train, y_test, scaler = preprocess_data()

# 2. Criar modelo
model = create_model()

# 3. Treinar
model, train_losses, val_losses = train_model(
    model=model,
    X_train=X_train,
    y_train=y_train,
    X_test=X_test,
    y_test=y_test,
    epochs=100,
    learning_rate=0.001
)

print("âœ… Treinamento concluÃ­do!")
```

### O que acontece durante o treinamento

```
Para cada Ã©poca (1 a 100):
â”‚
â”œâ”€â”€ FASE DE TREINO
â”‚   â”œâ”€â”€ model.train()           â†’ Ativa dropout
â”‚   â”œâ”€â”€ outputs = model(X_train)â†’ Forward pass
â”‚   â”œâ”€â”€ loss = MSE(outputs, y)  â†’ Calcula erro
â”‚   â”œâ”€â”€ optimizer.zero_grad()   â†’ Limpa gradientes
â”‚   â”œâ”€â”€ loss.backward()         â†’ Calcula gradientes
â”‚   â””â”€â”€ optimizer.step()        â†’ Atualiza pesos
â”‚
â””â”€â”€ FASE DE VALIDAÃ‡ÃƒO
    â”œâ”€â”€ model.eval()            â†’ Desativa dropout
    â”œâ”€â”€ with torch.no_grad()    â†’ Economiza memÃ³ria
    â””â”€â”€ val_loss = MSE(...)     â†’ Mede generalizaÃ§Ã£o
```

---

## Passo 5: Monitorar o Progresso

### SaÃ­da esperada durante o treinamento

```
============================================================
ğŸ‹ï¸ Iniciando treinamento...
============================================================

Epoch [ 10/100] | Train Loss: 0.002840 | Val Loss: 0.008114 | Time: 0.9s
Epoch [ 20/100] | Train Loss: 0.001384 | Val Loss: 0.005497 | Time: 1.8s
Epoch [ 30/100] | Train Loss: 0.001069 | Val Loss: 0.004543 | Time: 2.7s
Epoch [ 40/100] | Train Loss: 0.000932 | Val Loss: 0.003865 | Time: 3.6s
Epoch [ 50/100] | Train Loss: 0.000860 | Val Loss: 0.003440 | Time: 4.6s
Epoch [ 60/100] | Train Loss: 0.000806 | Val Loss: 0.003109 | Time: 5.5s
Epoch [ 70/100] | Train Loss: 0.000774 | Val Loss: 0.002867 | Time: 6.4s
Epoch [ 80/100] | Train Loss: 0.000748 | Val Loss: 0.002668 | Time: 7.3s
Epoch [ 90/100] | Train Loss: 0.000719 | Val Loss: 0.002488 | Time: 8.3s
Epoch [100/100] | Train Loss: 0.000699 | Val Loss: 0.002358 | Time: 9.2s

============================================================
âœ… Treinamento concluÃ­do!
============================================================
```

### Como interpretar

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTERPRETAÃ‡ÃƒO                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… BOM: Train Loss diminuindo                                  â”‚
â”‚     â†’ O modelo estÃ¡ aprendendo                                  â”‚
â”‚                                                                 â”‚
â”‚  âœ… BOM: Val Loss diminuindo                                    â”‚
â”‚     â†’ O modelo estÃ¡ generalizando (nÃ£o sÃ³ decorando)            â”‚
â”‚                                                                 â”‚
â”‚  âœ… BOM: Val Loss > Train Loss (mas nÃ£o muito)                  â”‚
â”‚     â†’ Normal, pois validaÃ§Ã£o usa dados nunca vistos             â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸ ATENÃ‡ÃƒO: Val Loss parou de diminuir                         â”‚
â”‚     â†’ Pode estar comeÃ§ando a overfitar                          â”‚
â”‚                                                                 â”‚
â”‚  âŒ PROBLEMA: Val Loss subindo enquanto Train desce             â”‚
â”‚     â†’ Overfitting! Pare o treino e ajuste                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GrÃ¡fico de diagnÃ³stico

```
Loss
  â”‚
  â”‚    â•²
  â”‚     â•²  Val Loss
  â”‚      â•²
  â”‚       â•²__________ â† Ideal: ambos descem e estabilizam
  â”‚        â•²
  â”‚         â•² Train Loss
  â”‚          â•²________
  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Ã‰pocas
    0    20    40    60    80    100
```

---

## Passo 6: Salvar o Modelo

### O que Ã© salvo automaticamente

```python
# O train.py salva automaticamente em models/model_lstm.pth
torch.save({
    'model_state_dict': model.state_dict(),
    'model_config': {
        'input_size': 1,
        'hidden_size': 50,
        'num_layers': 2,
        'dropout': 0.2
    },
    'train_losses': train_losses,
    'val_losses': val_losses,
    'final_train_loss': train_losses[-1],
    'final_val_loss': val_losses[-1]
}, 'models/model_lstm.pth')
```

### Verificar se foi salvo

```python
import os

if os.path.exists('models/model_lstm.pth'):
    print("âœ… Modelo salvo com sucesso!")
    size = os.path.getsize('models/model_lstm.pth') / 1024
    print(f"   Tamanho: {size:.1f} KB")
else:
    print("âŒ Modelo nÃ£o foi salvo")
```

### Artefatos gerados

```
models/
â”œâ”€â”€ model_lstm.pth          # Pesos do modelo treinado
â””â”€â”€ training_history.png    # GrÃ¡fico de loss ao longo das Ã©pocas
```

---

# PARTE 2: AVALIAÃ‡ÃƒO DO MODELO

---

## Passo 7: Carregar o Modelo Salvo

### CÃ³digo

```python
import torch
from model import StockLSTM

# 1. Carregar o checkpoint
checkpoint = torch.load('models/model_lstm.pth')

# 2. Recriar o modelo com a mesma arquitetura
model = StockLSTM(**checkpoint['model_config'])

# 3. Carregar os pesos treinados
model.load_state_dict(checkpoint['model_state_dict'])

# 4. Colocar em modo de avaliaÃ§Ã£o
model.eval()

print("âœ… Modelo carregado!")
print(f"   Train Loss final: {checkpoint['final_train_loss']:.6f}")
print(f"   Val Loss final:   {checkpoint['final_val_loss']:.6f}")
```

### Por que model.eval()?

```
model.train():
â”œâ”€â”€ Dropout ATIVO (20% dos neurÃ´nios desligados)
â””â”€â”€ Usado durante o treinamento

model.eval():
â”œâ”€â”€ Dropout DESATIVO (100% dos neurÃ´nios ativos)
â””â”€â”€ Usado para fazer previsÃµes reais
```

---

## Passo 8: Fazer PrevisÃµes

### CÃ³digo completo

```python
import torch
from preprocessing import preprocess_data

# Carregar dados de teste
X_train, X_test, y_train, y_test, scaler = preprocess_data()

# Fazer previsÃµes
model.eval()
with torch.no_grad():
    predictions = model(X_test)

# Converter para numpy
predictions_np = predictions.numpy()
actual_np = y_test.numpy()

print(f"PrevisÃµes feitas: {len(predictions_np)} amostras")
```

### Reverter normalizaÃ§Ã£o (voltar para R$)

```python
import numpy as np

# Os dados estÃ£o normalizados (0-1), precisamos reverter para R$
predictions_reais = scaler.inverse_transform(predictions_np)
actual_reais = scaler.inverse_transform(actual_np)

print(f"\nExemplos de previsÃµes:")
print(f"{'Previsto':>12} | {'Real':>12} | {'Erro':>12}")
print("-" * 42)
for i in range(5):
    prev = predictions_reais[i][0]
    real = actual_reais[i][0]
    erro = abs(prev - real)
    print(f"R$ {prev:>9.2f} | R$ {real:>9.2f} | R$ {erro:>9.2f}")
```

**SaÃ­da esperada:**
```
Exemplos de previsÃµes:
    Previsto |         Real |         Erro
------------------------------------------
R$    25.43 | R$    25.12 | R$     0.31
R$    24.89 | R$    24.95 | R$     0.06
R$    26.01 | R$    26.45 | R$     0.44
R$    25.78 | R$    25.50 | R$     0.28
R$    24.56 | R$    24.80 | R$     0.24
```

---

## Passo 9: Calcular MÃ©tricas

### MÃ©tricas principais para regressÃ£o

```python
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Calcular mÃ©tricas
mse = mean_squared_error(actual_reais, predictions_reais)
rmse = np.sqrt(mse)
mae = mean_absolute_error(actual_reais, predictions_reais)
mape = np.mean(np.abs((actual_reais - predictions_reais) / actual_reais)) * 100

print("\n" + "=" * 50)
print("ğŸ“Š MÃ‰TRICAS DE AVALIAÃ‡ÃƒO")
print("=" * 50)
print(f"MSE  (Mean Squared Error):     {mse:.4f}")
print(f"RMSE (Root Mean Squared Error): R$ {rmse:.2f}")
print(f"MAE  (Mean Absolute Error):     R$ {mae:.2f}")
print(f"MAPE (Mean Absolute % Error):   {mape:.2f}%")
print("=" * 50)
```

### O que cada mÃ©trica significa

| MÃ©trica | FÃ³rmula | InterpretaÃ§Ã£o |
|---------|---------|---------------|
| **MSE** | mÃ©dia(erroÂ²) | Penaliza erros grandes, em unidadesÂ² |
| **RMSE** | âˆšMSE | Erro mÃ©dio na mesma unidade (R$) |
| **MAE** | mÃ©dia(\|erro\|) | Erro mÃ©dio absoluto (R$) |
| **MAPE** | mÃ©dia(\|erro/real\|) Ã— 100 | Erro percentual mÃ©dio (%) |

### Exemplo de interpretaÃ§Ã£o

```
RMSE = R$ 1.17 significa:
â””â”€ Em mÃ©dia, o modelo erra cerca de R$ 1.17 na previsÃ£o

MAPE = 4.5% significa:
â””â”€ Em mÃ©dia, o modelo erra cerca de 4.5% do valor real
```

---

## Passo 10: Interpretar Resultados

### Tabela de referÃªncia para MAPE

| MAPE | Qualidade da PrevisÃ£o |
|------|----------------------|
| < 5% | Excelente |
| 5-10% | Boa |
| 10-20% | AceitÃ¡vel |
| 20-50% | RazoÃ¡vel |
| > 50% | Ruim |

### Visualizar previsÃµes vs reais

```python
import matplotlib.pyplot as plt

# Plotar comparaÃ§Ã£o
plt.figure(figsize=(12, 6))

# Ãšltimas 100 amostras para visualizaÃ§Ã£o
n_samples = 100
plt.plot(actual_reais[-n_samples:], label='Real', color='blue', linewidth=2)
plt.plot(predictions_reais[-n_samples:], label='Previsto', color='red', 
         linewidth=2, linestyle='--')

plt.title('PrevisÃ£o vs Valor Real (Ãšltimas 100 amostras)')
plt.xlabel('Amostra')
plt.ylabel('PreÃ§o (R$)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('models/predictions_vs_actual.png', dpi=150)
plt.show()

print("âœ… GrÃ¡fico salvo em models/predictions_vs_actual.png")
```

### DiagnÃ³stico final

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DIAGNÃ“STICO FINAL                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  SE MAPE < 10% e RMSE < R$ 2.00:                                â”‚
â”‚  âœ… Modelo estÃ¡ bom! Pode usar para previsÃµes                   â”‚
â”‚                                                                 â”‚
â”‚  SE MAPE entre 10-20%:                                          â”‚
â”‚  âš ï¸ Modelo aceitÃ¡vel, considere ajustes:                        â”‚
â”‚     - Mais Ã©pocas de treinamento                                â”‚
â”‚     - Ajustar hidden_size                                       â”‚
â”‚     - Coletar mais dados                                        â”‚
â”‚                                                                 â”‚
â”‚  SE MAPE > 20%:                                                 â”‚
â”‚  âŒ Modelo precisa de melhorias:                                â”‚
â”‚     - Revisar prÃ©-processamento                                 â”‚
â”‚     - Tentar arquitetura diferente                              â”‚
â”‚     - Verificar qualidade dos dados                             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. DiagnÃ³stico e Ajustes

### Se o modelo nÃ£o estÃ¡ bom, o que ajustar?

| Problema | Sintoma | SoluÃ§Ã£o |
|----------|---------|---------|
| **Underfitting** | Train e Val loss altos | â†‘ hidden_size, â†‘ epochs, â†‘ num_layers |
| **Overfitting** | Train baixo, Val alto | â†‘ dropout, â†“ epochs, early stopping |
| **ConvergÃªncia lenta** | Loss demora a cair | â†‘ learning_rate (com cuidado) |
| **Loss oscilando** | Sobe e desce muito | â†“ learning_rate |
| **Loss estagnado** | Para de diminuir | â†‘ learning_rate, mudar arquitetura |

### Ordem sugerida para tuning

```
1. Learning Rate (maior impacto)
   â””â”€ Teste: 0.01, 0.001, 0.0001

2. Hidden Size (capacidade do modelo)
   â””â”€ Teste: 32, 50, 100, 128

3. NÃºmero de Layers
   â””â”€ Teste: 1, 2, 3

4. Dropout (regularizaÃ§Ã£o)
   â””â”€ Teste: 0.1, 0.2, 0.3, 0.5

5. Epochs
   â””â”€ Comece com 100, aumente se loss ainda estiver caindo
```

### Exemplo de experimentos

```
Experimento 1: epochs=100, lr=0.001, hidden=50     â†’ MAPE: 8.5%
Experimento 2: epochs=150, lr=0.001, hidden=50     â†’ MAPE: 7.2% âœ“
Experimento 3: epochs=150, lr=0.0005, hidden=50    â†’ MAPE: 6.8% âœ“
Experimento 4: epochs=150, lr=0.0005, hidden=100   â†’ MAPE: 7.5% (piorou)
Experimento 5: epochs=150, lr=0.0005, hidden=50, dropout=0.3 â†’ MAPE: 6.1% âœ“

Melhor configuraÃ§Ã£o: Experimento 5
```

---

## 6. Checklist Final

### Antes do Treinamento

- [ ] Dados coletados e salvos em CSV
- [ ] Dados prÃ©-processados (normalizados, sequÃªncias criadas)
- [ ] Dados divididos em treino/teste
- [ ] Modelo criado com arquitetura definida
- [ ] HiperparÃ¢metros escolhidos

### Durante o Treinamento

- [ ] Train loss estÃ¡ diminuindo
- [ ] Val loss estÃ¡ diminuindo
- [ ] NÃ£o hÃ¡ sinais de overfitting
- [ ] Tempo de execuÃ§Ã£o estÃ¡ razoÃ¡vel

### ApÃ³s o Treinamento

- [ ] Modelo salvo em arquivo .pth
- [ ] GrÃ¡fico de histÃ³rico gerado
- [ ] MÃ©tricas calculadas (RMSE, MAE, MAPE)
- [ ] Resultados documentados

### AvaliaÃ§Ã£o

- [ ] PrevisÃµes feitas nos dados de teste
- [ ] NormalizaÃ§Ã£o revertida para R$
- [ ] MÃ©tricas interpretadas
- [ ] GrÃ¡fico de previsÃµes vs reais gerado
- [ ] DecisÃ£o: modelo estÃ¡ bom ou precisa ajustar?

---

## 7. GlossÃ¡rio

| Termo | DefiniÃ§Ã£o |
|-------|-----------|
| **Ã‰poca (Epoch)** | Uma passagem completa por todos os dados de treino |
| **Loss** | Medida do erro/imprecisÃ£o do modelo |
| **MSE** | Mean Squared Error - erro quadrÃ¡tico mÃ©dio |
| **RMSE** | Raiz do MSE - erro na mesma unidade dos dados |
| **MAE** | Mean Absolute Error - erro absoluto mÃ©dio |
| **MAPE** | Mean Absolute Percentage Error - erro percentual |
| **Forward Pass** | Dados entram no modelo e saem como previsÃ£o |
| **Backward Pass** | CÃ¡lculo de gradientes (backpropagation) |
| **Gradiente** | Indica quanto cada peso contribuiu para o erro |
| **Learning Rate** | Tamanho do passo na atualizaÃ§Ã£o dos pesos |
| **Adam** | Otimizador adaptativo (ajusta lr por parÃ¢metro) |
| **Overfitting** | Modelo decorou os dados ao invÃ©s de aprender |
| **Underfitting** | Modelo nÃ£o aprendeu o suficiente |
| **Dropout** | RegularizaÃ§Ã£o que desliga neurÃ´nios aleatoriamente |
| **Scaler** | Objeto que normaliza/desnormaliza os dados |
| **Checkpoint** | Arquivo com pesos salvos do modelo |

---

## Script Completo de ExecuÃ§Ã£o

```python
"""
Script completo para treinar e avaliar o modelo LSTM
Execute: python treinar_e_avaliar.py
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error

from preprocessing import preprocess_data
from model import create_model, StockLSTM
from train import train_model

# ============================================================
# PARTE 1: TREINAMENTO
# ============================================================

print("=" * 60)
print("ETAPA 1: Carregando dados...")
print("=" * 60)
X_train, X_test, y_train, y_test, scaler = preprocess_data()
print(f"âœ… Treino: {X_train.shape[0]} amostras")
print(f"âœ… Teste:  {X_test.shape[0]} amostras")

print("\n" + "=" * 60)
print("ETAPA 2: Criando modelo...")
print("=" * 60)
model = create_model()
n_params = sum(p.numel() for p in model.parameters())
print(f"âœ… Modelo criado: {n_params:,} parÃ¢metros")

print("\n" + "=" * 60)
print("ETAPA 3: Treinando...")
print("=" * 60)
model, train_losses, val_losses = train_model(
    model=model,
    X_train=X_train,
    y_train=y_train,
    X_test=X_test,
    y_test=y_test,
    epochs=100,
    learning_rate=0.001
)

# ============================================================
# PARTE 2: AVALIAÃ‡ÃƒO
# ============================================================

print("\n" + "=" * 60)
print("ETAPA 4: Avaliando...")
print("=" * 60)

model.eval()
with torch.no_grad():
    predictions = model(X_test)

# Reverter normalizaÃ§Ã£o
predictions_reais = scaler.inverse_transform(predictions.numpy())
actual_reais = scaler.inverse_transform(y_test.numpy())

# Calcular mÃ©tricas
mse = mean_squared_error(actual_reais, predictions_reais)
rmse = np.sqrt(mse)
mae = mean_absolute_error(actual_reais, predictions_reais)
mape = np.mean(np.abs((actual_reais - predictions_reais) / actual_reais)) * 100

print(f"\nğŸ“Š MÃ‰TRICAS:")
print(f"   RMSE: R$ {rmse:.2f}")
print(f"   MAE:  R$ {mae:.2f}")
print(f"   MAPE: {mape:.2f}%")

# DiagnÃ³stico
print(f"\nğŸ” DIAGNÃ“STICO:")
if mape < 5:
    print("   âœ… Excelente! Modelo muito preciso.")
elif mape < 10:
    print("   âœ… Bom! Modelo com boa precisÃ£o.")
elif mape < 20:
    print("   âš ï¸ AceitÃ¡vel. Considere ajustes para melhorar.")
else:
    print("   âŒ Precisa melhorar. Revise hiperparÃ¢metros e dados.")

print("\n" + "=" * 60)
print("âœ… PROCESSO CONCLUÃDO!")
print("=" * 60)
```

---

*Guia criado para auxiliar no treinamento e avaliaÃ§Ã£o do modelo LSTM de previsÃ£o de preÃ§os de aÃ§Ãµes.*
