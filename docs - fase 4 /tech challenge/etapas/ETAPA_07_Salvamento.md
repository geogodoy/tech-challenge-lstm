# ğŸ“Œ ETAPA 7: Salvamento e PersistÃªncia

## ğŸ“‹ Resumo
| Item | Valor |
|------|-------|
| **Status** | âœ… ConcluÃ­da |
| **Data** | 2026-02-19 |
| **Tempo Estimado** | 15 min |
| **Tempo Real** | ~10 min |

---

## ğŸ¯ Objetivo
Persistir o modelo treinado e todos os artefatos necessÃ¡rios para que possam ser carregados posteriormente para inferÃªncia (API) ou re-treinamento, sem perder a configuraÃ§Ã£o original.

---

## ğŸ“ ConexÃ£o com as Aulas

### Por que Salvar o Modelo?

> *"Um modelo de machine learning sem persistÃªncia Ã© como um programa que perde todo o estado quando fechado. O treinamento pode levar horas ou dias - seria desperdÃ­cio re-treinar toda vez."*

### Conceitos de SerializaÃ§Ã£o

> *"SerializaÃ§Ã£o Ã© o processo de converter objetos em memÃ³ria para um formato que pode ser armazenado em disco ou transmitido pela rede."*

---

## ğŸ“ Arquivos de PersistÃªncia

### Estrutura de Artefatos

```
models/
â”œâ”€â”€ model_lstm.pth          # Pesos e config do modelo (PyTorch)
â”œâ”€â”€ scaler.pkl              # Normalizador (scikit-learn)
â”œâ”€â”€ config.pkl              # ConfiguraÃ§Ãµes do pipeline
â”œâ”€â”€ training_history.png    # GrÃ¡fico de loss
â””â”€â”€ predictions_vs_actual.png # GrÃ¡fico de previsÃµes
```

---

## ğŸ’¾ 1. Salvamento do Modelo PyTorch

### O que Salvar?

```python
# Apenas o state_dict (RECOMENDADO)
torch.save(model.state_dict(), 'model.pth')

# OU modelo completo com metadados (MELHOR para deploy)
torch.save({
    'model_state_dict': model.state_dict(),
    'model_config': {...},
    'training_info': {...}
}, 'model.pth')
```

### Por que usar `state_dict()` e nÃ£o o modelo inteiro?

```
OpÃ§Ã£o 1: torch.save(model, 'model.pth')
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âŒ Salva o modelo inteiro
âŒ Depende da estrutura exata das classes
âŒ Problemas se mover arquivos ou renomear classes
âŒ Maior tamanho de arquivo

OpÃ§Ã£o 2: torch.save(model.state_dict(), 'model.pth')
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Salva apenas os pesos (parÃ¢metros)
âœ… Independente da localizaÃ§Ã£o do cÃ³digo
âœ… Mais flexÃ­vel para modificaÃ§Ãµes
âœ… Menor tamanho de arquivo
âœ… PadrÃ£o recomendado pelo PyTorch
```

### Nosso Checkpoint Completo

```python
# Arquivo: src/train.py - FunÃ§Ã£o save_trained_model()

def save_trained_model(model, train_losses, val_losses, save_path=None):
    """
    Salva o modelo treinado com todas as informaÃ§Ãµes necessÃ¡rias.
    """
    if save_path is None:
        save_path = MODELS_DIR / "model_lstm.pth"
    
    checkpoint = {
        # 1. PESOS DO MODELO
        # DicionÃ¡rio com todos os parÃ¢metros treinÃ¡veis
        # Formato: {'lstm.weight_ih_l0': tensor(...), 'lstm.weight_hh_l0': tensor(...), ...}
        'model_state_dict': model.state_dict(),
        
        # 2. CONFIGURAÃ‡ÃƒO DA ARQUITETURA
        # NecessÃ¡rio para recriar o modelo com mesma estrutura
        'model_config': {
            'input_size': 1,       # Features de entrada
            'hidden_size': 100,    # NeurÃ´nios LSTM (otimizado)
            'num_layers': 2,       # Camadas LSTM
            'dropout': 0.2         # Taxa de regularizaÃ§Ã£o
        },
        
        # 3. HISTÃ“RICO DE TREINAMENTO
        # Ãštil para anÃ¡lise e debugging
        'train_losses': train_losses,   # Lista de losses por Ã©poca
        'val_losses': val_losses,       # Lista de val losses por Ã©poca
        
        # 4. MÃ‰TRICAS FINAIS
        # Snapshot do estado final
        'final_train_loss': train_losses[-1],
        'final_val_loss': val_losses[-1],
        
        # 5. METADADOS (opcional, mas Ãºtil)
        'epochs_trained': len(train_losses),
        'best_val_loss': min(val_losses),
        'best_epoch': val_losses.index(min(val_losses)) + 1
    }
    
    torch.save(checkpoint, save_path)
    print(f"ğŸ’¾ Modelo salvo em: {save_path}")
```

### ConteÃºdo do `model_state_dict`

```python
# O que estÃ¡ dentro de model.state_dict():
{
    'lstm.weight_ih_l0': tensor([...]),  # Pesos input-hidden camada 0
    'lstm.weight_hh_l0': tensor([...]),  # Pesos hidden-hidden camada 0
    'lstm.bias_ih_l0': tensor([...]),    # Bias input-hidden camada 0
    'lstm.bias_hh_l0': tensor([...]),    # Bias hidden-hidden camada 0
    'lstm.weight_ih_l1': tensor([...]),  # Pesos input-hidden camada 1
    'lstm.weight_hh_l1': tensor([...]),  # Pesos hidden-hidden camada 1
    'lstm.bias_ih_l1': tensor([...]),    # Bias input-hidden camada 1
    'lstm.bias_hh_l1': tensor([...]),    # Bias hidden-hidden camada 1
    'fc.weight': tensor([...]),          # Pesos camada linear
    'fc.bias': tensor([...])             # Bias camada linear
}

# Exemplo de dimensÃµes para hidden_size=100:
lstm.weight_ih_l0: shape (400, 1)     # 4 gates Ã— 100 hidden Ã— 1 input
lstm.weight_hh_l0: shape (400, 100)   # 4 gates Ã— 100 hidden Ã— 100 hidden
```

---

## ğŸ’¾ 2. Salvamento do Scaler

### Por que Salvar o Scaler?

```
PROBLEMA:
â”€â”€â”€â”€â”€â”€â”€â”€â”€
Durante o treino, normalizamos os dados usando MinMaxScaler.
O scaler "aprendeu" os valores mÃ­nimo e mÃ¡ximo dos dados de treino.

Treino: preÃ§o min = R$ 3.24, max = R$ 27.38
Scaler transforma: R$ 15.31 â†’ 0.5 (meio da escala)

Se criarmos um NOVO scaler para inferÃªncia:
InferÃªncia: preÃ§o atual min = R$ 22.00, max = R$ 25.00
Novo scaler transforma: R$ 23.50 â†’ 0.5 (DIFERENTE!)

RESULTADO: PrevisÃµes completamente erradas!

SOLUÃ‡ÃƒO:
â”€â”€â”€â”€â”€â”€â”€â”€
Salvar o scaler original e usÃ¡-lo na inferÃªncia.
```

### CÃ³digo de Salvamento

```python
# Arquivo: src/preprocessing.py - FunÃ§Ã£o preprocess_data()

import joblib  # Biblioteca para serializaÃ§Ã£o de objetos Python

def preprocess_data(save_scaler=True):
    """
    PrÃ©-processa os dados e opcionalmente salva o scaler.
    """
    # NormalizaÃ§Ã£o
    scaler = MinMaxScaler(feature_range=(0, 1))
    data_scaled = scaler.fit_transform(data)
    
    # Salvar scaler para uso posterior
    if save_scaler:
        scaler_path = MODELS_DIR / "scaler.pkl"
        joblib.dump(scaler, scaler_path)
        print(f"ğŸ“ Scaler salvo em: {scaler_path}")
    
    return X_train, X_test, y_train, y_test, scaler
```

### ConteÃºdo do Scaler Salvo

```python
# O que estÃ¡ dentro do scaler:
{
    'feature_range': (0, 1),
    'data_min_': array([3.24]),      # PreÃ§o mÃ­nimo nos dados de treino
    'data_max_': array([27.38]),     # PreÃ§o mÃ¡ximo nos dados de treino
    'scale_': array([0.04144...]),   # 1 / (max - min)
    'min_': array([-0.1343...]),     # -min * scale
}

# FÃ³rmula de normalizaÃ§Ã£o:
# valor_normalizado = (valor_original - data_min) / (data_max - data_min)

# FÃ³rmula de desnormalizaÃ§Ã£o:
# valor_original = valor_normalizado * (data_max - data_min) + data_min
```

---

## ğŸ’¾ 3. Salvamento de ConfiguraÃ§Ãµes

### Arquivo `config.pkl`

```python
# Salvar configuraÃ§Ãµes do pipeline
import joblib

config = {
    'seq_length': 60,           # Janela temporal (dias)
    'train_split': 0.8,         # 80% treino, 20% teste
    'feature_column': 'Close',  # Coluna usada
    'ticker': 'PETR4.SA',       # Ativo
    'date_range': {
        'start': '2018-01-01',
        'end': '2024-01-01'
    }
}

joblib.dump(config, 'models/config.pkl')
```

---

## ğŸ”„ Carregamento para InferÃªncia

### Pipeline Completo de Carregamento

```python
def load_for_inference():
    """
    Carrega todos os artefatos necessÃ¡rios para fazer previsÃµes.
    
    Returns:
        model: Modelo LSTM pronto para inferÃªncia
        scaler: Normalizador para transformar novos dados
        config: ConfiguraÃ§Ãµes do pipeline
    """
    # 1. CARREGAR MODELO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    checkpoint = torch.load('models/model_lstm.pth', weights_only=False)
    
    # Recriar arquitetura (PRECISA da classe StockLSTM)
    from model import StockLSTM
    model = StockLSTM(**checkpoint['model_config'])
    
    # Carregar pesos
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # Modo avaliaÃ§Ã£o (IMPORTANTE!)
    model.eval()
    
    # 2. CARREGAR SCALER
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    import joblib
    scaler = joblib.load('models/scaler.pkl')
    
    # 3. CARREGAR CONFIG (opcional)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    config = joblib.load('models/config.pkl')
    
    return model, scaler, config
```

### Exemplo de Uso para PrevisÃ£o

```python
# Carregar artefatos
model, scaler, config = load_for_inference()

# Novos dados (Ãºltimos 60 dias)
new_data = get_last_60_days('PETR4.SA')  # Shape: (60, 1)

# Normalizar com o MESMO scaler do treino
new_data_normalized = scaler.transform(new_data)

# Converter para tensor
X_new = torch.FloatTensor(new_data_normalized).unsqueeze(0)  # Shape: (1, 60, 1)

# Fazer previsÃ£o
with torch.no_grad():
    prediction_normalized = model(X_new)

# Desnormalizar para R$
prediction_reais = scaler.inverse_transform(prediction_normalized.numpy())

print(f"PrevisÃ£o: R$ {prediction_reais[0][0]:.2f}")
```

---

## ğŸ“Š Tamanhos dos Arquivos

| Arquivo | Tamanho | ConteÃºdo |
|---------|---------|----------|
| `model_lstm.pth` | ~500 KB | Pesos (~121k parÃ¢metros Ã— 4 bytes) + metadados |
| `scaler.pkl` | ~1 KB | ParÃ¢metros de normalizaÃ§Ã£o |
| `config.pkl` | ~1 KB | ConfiguraÃ§Ãµes do pipeline |
| `training_history.png` | ~150 KB | GrÃ¡fico de loss |
| `predictions_vs_actual.png` | ~200 KB | GrÃ¡ficos de avaliaÃ§Ã£o |
| **TOTAL** | ~850 KB | Tudo necessÃ¡rio para deploy |

---

## âš ï¸ Boas PrÃ¡ticas de Salvamento

### 1. Versionar Modelos

```python
# Incluir versÃ£o no nome do arquivo
torch.save(checkpoint, f'models/model_lstm_v{version}.pth')

# Ou usar timestamp
from datetime import datetime
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
torch.save(checkpoint, f'models/model_lstm_{timestamp}.pth')
```

### 2. Validar Carregamento

```python
# Sempre testar se o modelo carrega corretamente
def validate_model_loading(model_path):
    """Verifica se o modelo carrega sem erros."""
    try:
        checkpoint = torch.load(model_path, weights_only=False)
        model = StockLSTM(**checkpoint['model_config'])
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        # Teste com input dummy
        dummy_input = torch.randn(1, 60, 1)
        with torch.no_grad():
            output = model(dummy_input)
        
        print(f"âœ… Modelo validado! Output shape: {output.shape}")
        return True
    except Exception as e:
        print(f"âŒ Erro ao carregar modelo: {e}")
        return False
```

### 3. NÃ£o Salvar Dados SensÃ­veis

```python
# EVITAR salvar dados de treino no checkpoint
checkpoint = {
    'model_state_dict': model.state_dict(),
    'model_config': {...},
    # NÃƒO INCLUIR: 'X_train': X_train, 'y_train': y_train
}
```

### 4. Usar `weights_only` Quando PossÃ­vel

```python
# Mais seguro (evita execuÃ§Ã£o de cÃ³digo arbitrÃ¡rio)
checkpoint = torch.load('model.pth', weights_only=True)

# NecessÃ¡rio se salvou objetos customizados
checkpoint = torch.load('model.pth', weights_only=False)
```

---

## ğŸ”„ Fluxo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUXO DE PERSISTÃŠNCIA                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TREINAMENTO                          INFERÃŠNCIA                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Treinar   â”‚                     â”‚  Carregar   â”‚            â”‚
â”‚  â”‚   Modelo    â”‚                     â”‚   Modelo    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                   â”‚                   â”‚
â”‚         â–¼                                   â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      model.pth      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚    Salvar   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ load_state  â”‚            â”‚
â”‚  â”‚ state_dict  â”‚                     â”‚    _dict    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                   â”‚                   â”‚
â”‚         â–¼                                   â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      scaler.pkl     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Salvar    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Carregar   â”‚            â”‚
â”‚  â”‚   Scaler    â”‚                     â”‚   Scaler    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                   â”‚                   â”‚
â”‚         â–¼                                   â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      config.pkl     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Salvar    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Carregar   â”‚            â”‚
â”‚  â”‚   Config    â”‚                     â”‚   Config    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                             â”‚                   â”‚
â”‚                                             â–¼                   â”‚
â”‚                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                                      â”‚   Prever    â”‚            â”‚
â”‚                                      â”‚  (API/CLI)  â”‚            â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist de ConclusÃ£o

### Modelo
- [x] `model_state_dict` salvo
- [x] `model_config` incluÃ­do no checkpoint
- [x] HistÃ³rico de losses salvo
- [x] MÃ©tricas finais incluÃ­das
- [x] Modelo carrega corretamente
- [x] PrevisÃ£o funciona apÃ³s carregamento

### Scaler
- [x] Scaler salvo em formato .pkl
- [x] Carrega corretamente com joblib
- [x] `inverse_transform` funciona

### ConfiguraÃ§Ãµes
- [x] `seq_length` documentado (60)
- [x] `train_split` documentado (0.8)
- [x] ParÃ¢metros de data documentados

### ValidaÃ§Ã£o
- [x] Modelo validado apÃ³s carregamento
- [x] Output shape correto
- [x] PrevisÃµes fazem sentido

---

## ğŸ”— PrÃ³xima Etapa

**â†’ ETAPA 8: API FastAPI**
- Criar endpoints `/predict` e `/health`
- Carregar modelo na inicializaÃ§Ã£o
- Receber dados via JSON
- Retornar previsÃµes em R$
