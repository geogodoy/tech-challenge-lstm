Este material educativo detalha as diversas metodologias de aprendizado de máquina aplicadas ao desenvolvimento e à manutenção de redes neurais profundas em cenários reais. O texto explora a transição da teoria para a prática, abrangendo desde o aprendizado supervisionado com dados rotulados até o aprendizado por reforço baseado em tentativas e recompensas, passando por abordagens não supervisionadas e híbridas. Além das arquiteturas técnicas, a fonte enfatiza a importância da engenharia de machine learning, destacando o monitoramento de mudanças nos padrões de dados e a necessidade de escalabilidade e integração contínua para garantir a eficácia dos modelos em produção. O objetivo central é capacitar o leitor a implementar soluções robustas que se adaptem dinamicamente às demandas de ambientes corporativos e tecnológicos em constante evolução.

MACHINE LEARNING ENGINEERING
FASE 4 AULA 04 - TÉCNICAS DE
APLICAÇÃO DE REDES NEURAIS PROFUNDAS
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
POS TECH
Técnicas de Aplicação de Redes Neurais Profundas
O QUE VEM POR AÍ?
.3
HANDS ON
4
SAIBA MAIS
5
O QUE VOCÊ VIU NESTA AULA?
.20
REFERÊNCIAS
21
SUMÁRIO
FIAP
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Página 2 de 23
Técnicas de Aplicação de Redes Neurais Profundas
O QUE VEM POR AÍ?
Página 3 de 23
Inicialmente, abordaremos o aprendizado supervisionado, em que as redes neurais são treinadas com um conjunto claro de dados rotulados, permitindo que o modelo faça previsões ou classificações precisas com base nesse treinamento direcionado.
Avançando, exploraremos o aprendizado não supervisionado, uma técnica crucial para entender padrões ocultos em dados não rotulados. Discutiremos como as redes neurais podem identificar estruturas e agrupamentos intrínsecos nos dados, adaptando-se a novas categorias e emergências sem a necessidade de intervenção externa.
Além disso, o aprendizado semi-supervisionado será um tópico chave, em que combinaremos as forças dos métodos supervisionados e não supervisionados para melhorar o desempenho do modelo com uma quantidade limitada de dados rotulados.
Finalmente, discutiremos a aprendizagem por reforço, em que as redes neurais são treinadas para tomar decisões por meio de tentativas e erros, recebendo recompensas por ações bem-sucedidas.
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
HANDS ON
Página 4 de 23
Nesta aula, vamos aprofundar nossa compreensão sobre como implementar e manter redes neurais profundas em ambientes reais de produção.
Exploraremos aspectos críticos como a adaptação dos modelos às mudanças contínuas em padrões de dados e comportamentos de usuários, essenciais para manter a eficácia das redes neurais em aplicações dinâmicas.
Você aprenderá como ajustar arquiteturas e parâmetros de redes para responder eficientemente a essas mudanças, utilizando técnicas avançadas de aprendizado.
FIA
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
SAIBA MAIS
Página 5 de 23
Além de aprender como implementar e manter redes neurais profundas em ambientes reais de produção, também discutiremos a escalabilidade e a performance dessas redes, enfatizando métricas de qualidade e estratégias para estabelecer limites operacionais que assegurem a eficiência e a eficácia dos modelos.
A integração contínua e as atualizações dos sistemas serão exploradas em detalhes, oferecendo insights sobre como gerenciar o lançamento de novas versões de modelos sem interrupções. Essas práticas são vitais para garantir que as redes neurais profundas permaneçam relevantes e precisas à medida que escalam para atender a demandas crescentes.
Prepare-se para ver esses conceitos aplicados por meio de exemplos de código Python que ilustram cada ponto em nosso ambiente de aprendizado interativo. Por exemplo: vamos demonstrar como implementar diferentes estratégias de aprendizado de redes neurais, como o aprendizado supervisionado, não supervisionado, semi- supervisionado e por reforço, com o seguinte código:
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
# Configurando a semente para reprodutibilidade torch.manual seed (0)
# Gerando dados simulados
data = torch.rand(1000, 10) %23 1000 amostras, 10 características labels = (torch.sum (data, axis=1) > 5).float() # Classificação binária baseada na soma das características
# Divisão de dados para treinamento e teste
X train, X test, y_train, y_test = train_test_split(data, labels, test size=0.2, random state=0)
X_train = torch.tensor (X_train, dtype=torch.float32) X_test = torch.tensor (X test, dtype=torch.float32) y_train = torch.tensor(y_train, dtype=torch.float32) y_test = torch.tensor(y_test, dtype=torch.float32)
# Criando DataLoaders
train_data = TensorDataset (X_train, y_train) test_data = TensorDataset (X_test, y_test)
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 6 de 23
train loader shuffle=True) test loader shuffle=False)
=
DataLoader(train_data,
batch_size $=32$,
=
DataLoader (test_data,
batch_size $=32$,
# Definindo o modelo
class NeuralNetwork(nn.Module):
def
init
(self):
super (NeuralNetwork, self). _init()
self.layer1 = nn. Linear (10, 64)
self.relu = nn. ReLU ()
self.dropout = nn. Dropout(0.5)
self.layer2 = nn. Linear (64, 32)
self.output_layer = nn. Linear(32, 1)
self.sigmoid = nn.Sigmoid()
def forward(self, x):
$x=$ self.relu(self.layer1(x))
$x=$ self.dropout(x)
$x=$ self.relu(self.layer2(x))
$x=$ self.sigmoid(self.output_layer(x))
return x
model = NeuralNetwork()
# Definindo o otimizador e a função de perda
optimizer = optim.Adam (model.parameters(), $lr=0.001)$ criterion = nn.BCELoss()
# Função para executar o treinamento
def train model (model, train loader, criterion, optimizer):
model.train ()
for inputs, targets in train _loader:
optimizer.zero grad()
outputs = model (inputs)
loss = criterion (outputs, targets.view(-1, 1))
loss.backward()
optimizer.step()
# Função para avaliação
def evaluate_model (model, test_loader, criterion):
model.eval()
total loss, total accuracy $=0$ 0,0
with torch.no_grad():
for inputs, targets in test loader:
outputs = model (inputs)
loss = criterion (outputs, targets.view(-1, 1)) total loss += loss.item()
=
accuracy ((outputs > 0.5) ==
1)).float().mean()
total_accuracy += accuracy.item()
targets.view(-1,
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 7 de 23
=
avg_loss = total_loss / len (test_loader) avg_accuracy total_accuracy / len(test_loader) return avg_loss, avg_accuracy
# Treinando e avaliando o modelo
train_model (model, train loader, criterion, optimizer)
test loss, test accuracy
criterion)
print (f'Test
= evaluate model (model, test loader,
Loss:
{test_loss:.4f},
Test
{test_accuracy:.4f}')
Accuracy:
Código-fonte 1 - Exemplo de Implementação de Redes Neurais Profundas Fonte: elaborado pelo autor (2024)
Este exemplo ilustra o uso de redes neurais profundas para classificação em um cenário de aprendizado supervisionado. Demonstraremos também como adaptar este modelo para aprendizado não supervisionado e semi-supervisionado, além de explorar técnicas de aprendizado por reforço para completar nosso estudo sobre a adaptabilidade das redes neurais profundas a diferentes cenários de aprendizado.
Além disso, exploraremos as diversas vertentes da aprendizagem em redes neurais profundas, uma área crucial na evolução da inteligência artificial. À medida que nos aprofundamos além dos conceitos teóricos apresentados anteriormente, vamos entender como as redes neurais profundas são implementadas e mantidas em ambientes reais de produção. Discutiremos aspectos essenciais como ajuste fino de modelos para diferentes tipos de aprendizado, desde supervisionado até por reforço, destacando as peculiaridades de cada abordagem e como elas impactam a eficácia das redes neurais em tarefas específicas.
Além disso, abordaremos questões críticas como o monitoramento de drifts de conceito em modelos de aprendizagem contínua, um componente vital para garantir que as mudanças nas distribuições de dados ou nas dinâmicas do ambiente não prejudiquem a performance dos modelos. Como podemos ajustar os hiperparâmetros das redes para manter sua precisão frente a essas mudanças contínuas?
Também será discutida a escalabilidade e o desempenho dessas redes, enfatizando métricas de qualidade e estratégias para definir limites operacionais que assegurem eficiência e eficácia. A integração contínua e as atualizações sistemáticas dos modelos serão exploradas, demonstrando como novas versões são desenvolvidas e implementadas sem interrupções, uma prática essencial para sustentar a relevância e a precisão das soluções baseadas em aprendizado profundo.
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 8 de 23
Preparado(a) para mergulhar em como teorias são transformadas em práticas robustas que impulsionam negócios e atendem a usuários em constante evolução?
Aprendizagem Supervisionada
A aprendizagem supervisionada, conforme explorada em várias literaturas recentes, envolve a modelagem de uma função que estima a relação entre variáveis de entrada e saída com base em um conjunto de dados rotulado. Este processo se baseia fundamentalmente em encontrar os parâmetros que minimizam uma função de perda, refletindo a discrepância entre as previsões do modelo e os valores reais nos dados de treinamento.
O livro "Machine Learning - A Probabilistic Perspective" de Kevin P. Murphy (2024) detalha que o coração da aprendizagem supervisionada reside na classificação e na regressão. A classificação envolve categorizar entradas em classes distintas, utilizando modelos que podem ser tanto binários quanto multiclasses. Por outro lado, a regressão lida com a previsão de um valor contínuo. Murphy também aponta a importância de entender as distribuições dos dados e como diferentes modelos podem ser ajustados para capturar essas relações complexas.
Já no livro "Mathematical Aspects of Deep Learning" de Philipp Grohs e Gitta Kutyniok (2023), a discussão se aprofunda na construção do espaço de hipóteses e na minimização do risco empírico, elementos cruciais para desenvolver modelos de aprendizagem eficazes. Eles descrevem como os modelos lineares podem ser estendidos para modelos generalizados lineares ou até mesmo redes neurais, dependendo da complexidade da função objetivo e da arquitetura desejada.
Trata-se de uma abordagem central no campo da inteligência artificial, em que um modelo aprende a mapear entradas e saídas com base em um conjunto de dados rotulado. Este processo envolve a minimização de uma função de perda que quantifica a diferença entre as previsões do modelo e os valores reais nos dados de treinamento. A eficiência e a eficácia deste aprendizado dependem significativamente da natureza dos dados envolvidos, que podem ser estruturados ou não estruturados.
Dados estruturados referem-se a dados que são organizados em um formato fixo e pré-definido, geralmente em tabelas ou bancos de dados relacionais. Exemplos incluem registros de clientes, transações financeiras e dados de sensores. Esses dados são caracterizados por serem facilmente pesquisáveis e analisáveis devido à
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 9 de 23
sua organização em colunas e linhas com tipos de dados específicos. Na aprendizagem supervisionada, os dados estruturados são usados para tarefas como classificação e regressão.
Em redes neurais profundas, o processamento de dados estruturados pode ser conduzido por meio de redes totalmente conectadas, também conhecidas como Fully Connected Networks ou MLPs. Essas redes são eficazes em capturar padrões complexos e não lineares nos dados. Por exemplo: em uma tarefa de previsão de risco de crédito, os atributos do cliente, como renda, histórico de crédito e idade, podem ser alimentados em uma rede neural profunda para prever a probabilidade de inadimplência.
Dados não estruturados, por outro lado, não seguem um formato específico e incluem textos, imagens, áudios e vídeos. Esses dados são mais desafiadores de processar e analisar devido à sua falta de estrutura. Exemplos incluem e-mails, postagens em redes sociais, documentos de texto e vídeos. Para dados não estruturados, diferentes arquiteturas de redes neurais profundas são empregadas.
Redes Neurais Convolucionais (CNNs) são utilizadas principalmente para o processamento de imagens e vídeos. As CNNs são eficazes em capturar hierarquias de características em dados visuais, começando por detectar bordas e texturas nas primeiras camadas e avançando para a detecção de objetos completos nas camadas mais profundas. Por exemplo: em uma tarefa de classificação de imagens, uma CNN pode ser treinada para identificar diferentes tipos de animais em fotos.
Redes Neurais Recorrentes (RNNs) são adequadas para dados sequenciais, como textos e áudios. As RNNs são projetadas para capturar dependências temporais, sendo particularmente úteis em tarefas como tradução automática, em que a sequência de palavras é crucial. Modelos avançados, como LSTMs e GRUs, são variantes de RNNs que mitigam problemas como o desvanecimento do gradiente, permitindo a captura de dependências de longo prazo.
Uma arquitetura recente que revolucionou o processamento de linguagem natural (PLN) são os transformadores. Os transformadores utilizam mecanismos de atenção que permitem o processamento paralelo de sequências de dados, capturando relacionamentos de longo alcance mais eficientemente do que as RNNs. Modelos
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 10 de 23
como BERT e GPT, baseados em transformadores, têm alcançado resultados de ponta em tarefas de PLN.
A aprendizagem supervisionada em redes neurais profundas integra dados estruturados e não estruturados de forma a maximizar a precisão e a generalização do modelo. Por exemplo: um sistema de recomendação pode combinar dados estruturados, como histórico de compras e características demográficas, com dados não estruturados, como avaliações de produtos e comentários de clientes, para fornecer recomendações personalizadas mais precisas.
A integração de ambas as formas de dados requer um cuidadoso pré- processamento e engenharia de características, além de uma escolha apropriada de arquitetura de rede neural que possa lidar com a complexidade e a natureza dos dados. Esta abordagem holística permite que as redes neurais profundas ofereçam soluções robustas e eficientes em uma vasta gama de aplicações no mundo real, desde diagnósticos médicos até sistemas de recomendação avançados.
Aprendizagem não supervisionada
A aprendizagem não supervisionada, conforme descrita por autores como Kevin P. Murphy em "Machine Learning - A Probabilistic Perspective" e Simon J. D. Prince em "Understanding Deep Learning" (2024), envolve a modelagem de dados sem a necessidade de rótulos. O principal objetivo é descobrir a estrutura inerente ou padrões dentro dos dados, sem qualquer orientação explícita sobre quais são os resultados corretos. Em contraste com a aprendizagem supervisionada, em que se tem uma relação direta entre entrada e saída, na aprendizagem não supervisionada busca-se entender a distribuição dos dados e como os diferentes atributos estão correlacionados.
Murphy explora detalhadamente que a aprendizagem não supervisionada pode ser vista como uma tarefa de estimação de densidade, em que se deseja construir modelos que descrevam a distribuição $p(x_{i}|\theta)$ dos dados. Isso se difere significativamente da aprendizagem supervisionada, que é essencialmente uma estimação de densidade condicional $p(y_{i}|x_{i},\theta)$. Na aprendizagem não supervisionada, cada vetor de características $x_{i}$ precisa ser modelado de maneira multivariada em oposição às variáveis individuais que geralmente são preditas na aprendizagem supervisionada. Um dos maiores desafios é a complexidade da
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 11 de 23
modelagem probabilística multivariada, o que requer técnicas avançadas de modelagem e estimação.
Prince, por outro lado, foca em modelos generativos dentro da aprendizagem não supervisionada, que são capazes de sintetizar novos exemplos de dados que são estatisticamente indistinguíveis dos dados de treinamento. Modelos generativos podem explicitamente descrever a distribuição de probabilidade dos dados de entrada e gerar novos exemplos por meio de amostragem dessa distribuição. Esses modelos são particularmente úteis em aplicações em que é importante capturar a variabilidade e a complexidade dos dados, como em tarefas de geração de imagens, textos ou sons.
Uma técnica importante na aprendizagem não supervisionada é a análise de componentes principais (PCA), que busca reduzir a dimensionalidade dos dados enquanto retém a maior quantidade possível de variância. A PCA é amplamente utilizada em pré-processamento de dados, em que se deseja simplificar o modelo sem perder a informação crítica contida nos dados originais. A redução de dimensionalidade facilita não apenas a visualização dos dados, mas também melhora a eficiência dos algoritmos subsequentes ao reduzir o número de variáveis a serem consideradas.
Para exemplificar, considere o uso de autoencoders, uma arquitetura de rede neural profunda que se destaca na aprendizagem não supervisionada. Um autoencoder é composto de duas partes: um codificador que reduz a dimensionalidade dos dados de entrada e um decodificador que tenta reconstruir os dados originais a partir dessa representação compacta. Esta técnica não só é útil para compressão de dados, mas também para detectar anomalias, em que dados que não podem ser bem reconstruídos pelo autoencoder são considerados anômalos.
A flexibilidade das técnicas de aprendizagem não supervisionada abre um vasto leque de possibilidades para a descoberta de padrões e estruturas nos dados, permitindo uma compreensão mais profunda e insights que poderiam não ser aparentes de outra forma. A aprendizagem não-supervisionada em redes neurais profundas é um paradigma de aprendizado em que o modelo é treinado utilizando dados que não possuem rótulos ou respostas conhecidas.
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 12 de 23
Diferente da aprendizagem supervisionada, em que cada exemplo de treinamento é acompanhado de um rótulo, a aprendizagem não-supervisionada busca identificar padrões, estruturas ou representações nos dados de forma autônoma. Essa abordagem é especialmente útil quando se lida com grandes volumes de dados, em que a rotulagem manual seria impraticável ou impossível.
No contexto de dados estruturados, que são organizados em um formato tabular com atributos bem definidos, a aprendizagem não-supervisionada pode ser utilizada para diversas tarefas como agrupamento, redução de dimensionalidade e detecção de anomalias. Técnicas como redes neurais autoencoders são amplamente utilizadas para essas tarefas. Um autoencoder é uma rede neural que é treinada para copiar suas entradas para suas saídas. Ele possui uma camada de codificação que reduz a dimensionalidade dos dados e uma camada de decodificação que reconstrói os dados a partir dessa representação compacta.
A ideia é que, ao forçar a rede a aprender uma representação comprimida dos dados, ela capture as características mais importantes e as relações intrínsecas entre os atributos. Por exemplo: em um conjunto de dados de clientes de um banco, um autoencoder pode ser utilizado para identificar padrões de comportamento que são comuns a grupos de clientes, o que pode ser útil para segmentação de mercado ou análise de risco.
Além dos autoencoders, os algoritmos de clustering como o K-means podem ser combinados com redes neurais para melhorar a qualidade dos agrupamentos. Redes neuronais profundas podem ser usadas para aprender representações de características que são mais adequadas para clustering do que as características originais. Este processo envolve o uso de camadas ocultas para transformar os dados de entrada em um espaço em que as diferenças entre os clusters são mais pronunciadas. Uma vez que essa transformação é aprendida, técnicas tradicionais de clustering podem ser aplicadas com maior eficácia.
Quando se trata de dados não estruturados, como imagens, texto, áudio e vídeo, a aprendizagem não-supervisionada em redes neurais profundas torna-se ainda mais crucial. As Convolutional Neural Networks (CNNs) podem ser adaptadas para tarefas não-supervisionadas em dados de imagem através de autoencoders convolucionais. Assim como os autoencoders tradicionais, esses modelos aprendem
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 13 de 23
a codificar e decodificar imagens, mas utilizam convoluções para capturar padrões espaciais.
Isso permite que a rede aprenda características hierárquicas nas imagens, desde bordas simples até objetos complexos. Por exemplo: em um grande conjunto de imagens médicas, um autoencoder convolucional pode ser utilizado para aprender representações que ajudam na identificação de estruturas anatômicas ou na detecção de anomalias sem a necessidade de rótulos explícitos.
No domínio do processamento de linguagem natural (PLN), modelos como word2vec e GloVe utilizam aprendizagem não-supervisionada para aprender representações densas de palavras, conhecidas como embeddings. Esses embeddings capturam semânticas e relações contextuais entre palavras com base em grandes corpora de texto. Redes neurais profundas, como Transformers, podem ser treinadas de maneira não-supervisionada para gerar essas representações.
Um Transformer, por exemplo, pode ser treinado para prever palavras mascaradas em um texto, o que força o modelo a aprender relações contextuais e semânticas profundas entre as palavras. Essas representações podem então ser utilizadas para tarefas subsequentes de PLN, como classificação de texto, tradução automática ou sumarização, melhorando significativamente a performance dos modelos supervisionados.
Outra aplicação interessante da aprendizagem não-supervisionada em dados não estruturados é na área de geração de conteúdo. Modelos generativos, como as Generative Adversarial Networks (GANs), utilizam aprendizagem não-supervisionada para criar exemplos de dados que são indistinguíveis dos dados reais. As GANS consistem em duas redes neurais competindo entre si: um gerador que tenta criar dados falsos que parecem reais e um discriminador que tenta distinguir entre dados reais e falsos.
Este processo adversarial resulta em um gerador capaz de criar dados altamente realistas, sejam eles imagens, áudio ou até mesmo texto. Por exemplo: GANs têm sido utilizadas para gerar imagens sintéticas de alta qualidade para aumentar conjuntos de dados de treinamento ou criar arte digital.
Além disso, redes neurais recorrentes (RNNs) e suas variantes, como LSTMs e GRUS, podem ser aplicadas em tarefas não-supervisionadas para modelar
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 14 de 23
sequências temporais. Em um conjunto de dados de séries temporais, uma RNN pode ser treinada para prever a próxima sequência de dados com base nas sequências anteriores, capturando padrões temporais complexos. Este tipo de abordagem pode ser utilizado para detecção de anomalias em fluxos de dados contínuos, como monitoramento de máquinas em fábricas ou análise de comportamentos em sistemas financeiros.
A aprendizagem não-supervisionada em redes neurais profundas, portanto, envolve uma variedade de técnicas e arquiteturas que são adaptadas para diferentes tipos de dados e problemas. Seja lidando com dados estruturados ou não estruturados, o objetivo é sempre descobrir padrões ocultos e representações significativas que podem ser utilizadas para melhorar a compreensão e a manipulação dos dados. As capacidades de autodescoberta e auto-organização das redes neurais profundas tornam-nas ferramentas poderosas para a exploração e análise de grandes volumes de dados sem a necessidade de supervisão explícita.
Aprendizagem Semi-supervisionada
A aprendizagem semi-supervisionada é uma abordagem que combina tanto elementos de aprendizagem supervisionada quanto de aprendizagem não supervisionada. Esta técnica é particularmente útil quando temos uma grande quantidade de dados não rotulados e uma quantidade relativamente pequena de dados rotulados. As redes neurais profundas, especialmente em cenários de aprendizagem semi-supervisionada, demonstram uma eficácia significativa na utilização desses dois tipos de dados para melhorar a precisão e a generalização dos modelos.
No livro "Understanding Deep Learning" de Simon J.D. Prince, a aprendizagem semi-supervisionada é destacada como uma estratégia crucial em situações em que a obtenção de rótulos para todos os dados disponíveis é inviável devido ao custo ou tempo envolvidos. Prince enfatiza a importância de utilizar técnicas como autoencoder, em que a rede neural é treinada para reconstruir a entrada a partir de uma representação comprimida, permitindo que a rede aprenda características relevantes dos dados não rotulados. Este aprendizado das características pode então ser transferido para uma tarefa supervisionada com um conjunto de dados rotulados menor.
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 15 de 23
Kevin P. Murphy, em "Machine Learning: A Probabilistic Perspective", discute como a aprendizagem semi-supervisionada pode ser vista como uma extensão da aprendizagem supervisionada tradicional. Ele apresenta métodos probabilísticos que podem ser aplicados a modelos semi-supervisionados, como o uso de misturas de Gaussianas para modelar a distribuição dos dados e inferir as classes dos dados não rotulados. Murphy também aborda o uso de regularização para integrar dados rotulados e não rotulados de maneira eficiente, melhorando a robustez do modelo.
Christopher M. Bishop, no livro "Deep Learning: Foundations and Concepts" (2024), aprofunda-se nas arquiteturas que são particularmente eficazes em cenários semi-supervisionados. Ele descreve o uso de redes adversariais generativas (GANs) e variational autoencoders (VAEs) como ferramentas poderosas para gerar representações latentes dos dados. Estas representações podem ser usadas para aumentar o conjunto de dados rotulados por meio da síntese de novos exemplos ou para ajustar o modelo às características subjacentes dos dados não rotulados.
A prática de combinar diferentes tipos de dados é ilustrada por meio de técnicas como a co-training, em que dois modelos são treinados simultaneamente em subconjuntos diferentes dos dados rotulados e não rotulados, cada um auxiliando 0 outro ao rotular novos exemplos. Esta técnica é especialmente útil quando os dados possuem diferentes visões ou representações. Outra abordagem prática é a pseudo- rotulação, em que o modelo é inicialmente treinado com dados rotulados, e depois usado para rotular os dados não rotulados, que são então reutilizados para refinar o modelo.
O uso de redes neurais profundas em aprendizagem semi-supervisionada pode ser implementado de várias maneiras. Um exemplo típico seria o uso de uma arquitetura de autoencoder seguido por uma camada de classificação supervisionada. Este modelo pode ser treinado inicialmente com dados não rotulados para aprender uma representação útil e, em seguida, ajustado com dados rotulados para a tarefa específica de classificação. A capacidade das redes profundas de capturar características complexas e não lineares dos dados faz com que elas sejam particularmente adequadas para este tipo de tarefa.
Em ambientes nos quais a rotulação de dados é dispendiosa ou demorada, a aprendizagem semi-supervisionada permite que os modelos aprendam de maneira mais robusta ao utilizar um grande volume de dados não rotulados, complementado
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 16 de 23
por uma pequena quantidade de dados rotulados. Esta abordagem é particularmente valiosa em situações em que o acesso a grandes quantidades de dados rotulados é limitado.
Os dados estruturados, que são organizados em formatos predefinidos como tabelas ou bancos de dados relacionais, facilitam a aplicação de técnicas semi- supervisionadas devido à clareza das relações entre atributos e rótulos. Nesses casos, modelos como autoencoders, redes neurais convolucionais (CNNs) e redes neurais recorrentes (RNNs) podem ser treinados inicialmente com dados não rotulados para aprender representações úteis das entradas.
Posteriormente, o ajuste fino com dados rotulados pode ser realizado para melhorar a precisão do modelo em tarefas específicas. A abordagem de autoencoder, por exemplo, pode ser utilizada para aprender uma representação compacta dos dados estruturados. Em seguida, uma camada adicional pode ser adicionada e treinada com os poucos dados rotulados disponíveis para realizar tarefas de classificação ou regressão.
No caso de dados não estruturados, como texto, imagens ou áudio, a aprendizagem semi-supervisionada enfrenta desafios adicionais devido à diversidade e complexidade das representações de dados. No entanto, técnicas avançadas como as redes generativas adversariais (GANs) e os transformadores (transformers) têm se mostrado como uma grande promessa. As GANs, por exemplo, podem gerar dados sintéticos que imitam as características dos dados reais, ajudando a aumentar o conjunto de dados rotulados e a melhorar o treinamento do modelo.
Por outro lado, os transformers, especialmente em aplicações de processamento de linguagem natural (PLN), podem ser pré-treinados em grandes corpora de texto não rotulado para aprender as representações contextuais das palavras. Posteriormente, o ajuste fino com um conjunto menor de dados rotulados permite que o modelo alcance altos níveis de precisão em tarefas específicas de PLN, como classificação de texto ou tradução automática.
A técnica de co-training é outra abordagem popular na aprendizagem semi- supervisionada, em que dois ou mais modelos são treinados em diferentes vistas dos dados. Cada modelo é inicialmente treinado com dados rotulados e, em seguida, usa suas previsões para rotular novos dados não rotulados. Esses novos dados rotulados
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 17 de 23
são então utilizados para treinar os outros modelos, criando um ciclo de feedback que reforça o aprendizado mútuo. Esta abordagem é particularmente eficaz quando diferentes vistas dos dados capturam informações complementares, como texto е imagem em uma tarefa de análise multimodal.
Além disso, técnicas de regularização como Dropout e Batch Normalization são frequentemente utilizadas em aprendizagem semi-supervisionada para evitar o overfitting e melhorar a generalização dos modelos. O Dropout, por exemplo, desativa aleatoriamente uma fração dos neurônios durante o treinamento, forçando a rede a aprender representações redundantes que são mais robustas a variações nos dados de entrada. Já Batch Normalization, por outro lado, normaliza as ativações das camadas intermediárias, acelerando o treinamento e melhorando a estabilidade do modelo.
A utilização de pseudo-rótulos é uma prática comum na aprendizagem semi- supervisionada, em que o modelo inicial é treinado com dados rotulados e, em seguida, usado para prever rótulos de dados não rotulados. Esses pseudo-rótulos são então incorporados ao conjunto de dados de treinamento, permitindo que o modelo refine suas previsões e melhore sua precisão iterativamente. Esta abordagem é particularmente útil em cenários nos quais os dados rotulados são escassos, mas os dados não rotulados estão amplamente disponíveis.
A aprendizagem semi-supervisionada em redes neurais profundas é uma área dinâmica e em crescimento, que explora a complementaridade entre dados rotulados e não rotulados para construir modelos mais eficientes e precisos. Seja em dados estruturados ou não estruturados, as técnicas semi-supervisionadas oferecem uma abordagem poderosa para lidar com a escassez de rótulos, aproveitando ao máximo os recursos disponíveis para melhorar o desempenho do modelo em diversas tarefas de aprendizado de máquina.
Aprendizagem por Reforço
A aprendizagem por reforço é um paradigma fundamental na área de machine learning, sendo discutido em profundidade em várias literaturas, incluindo "Machine Learning A Probabilistic Perspective" de Kevin P. Murphy e "Understanding Deep Learning" de Simon J. D. Prince. Este método envolve a ideia de um agente que interage com um ambiente, realizando ações que resultam em mudanças de estado e
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 18 de 23
recompensas. O objetivo principal é aprender uma política que maximiza a recompensa acumulada ao longo do tempo.
No contexto de redes neurais profundas, a aprendizagem por reforço se destaca por sua capacidade de lidar com problemas em que as decisões são tomadas sequencialmente e as recompensas podem ser atrasadas. Um dos conceitos centrais é o processo de decisão de Markov (MDP), que formaliza o ambiente em que o agente opera. Um MDP é definido por um conjunto de estados, um conjunto de ações, uma função de transição de estados e uma função de recompensa.
Em "Machine Learning - A Probabilistic Perspective", Murphy explora métodos como Q-learning e aprendizado baseado em políticas. O Q-learning é um algoritmo de aprendizagem por reforço fora da política que busca aprender a função de ação- valor $Q(s,a)$ que representa a recompensa esperada de realizar uma ação a em um estado s. O aprendizado é realizado por meio de atualizações iterativas baseadas na equação de Bellman. Já os métodos baseados em políticas, como o gradiente de política, diretamente aprendem uma política $\pi(a|s)$, que é a probabilidade de tomar uma ação a dado um estado s. Estes métodos são úteis em ambientes em que a função de valor é difícil de estimar.
Um exemplo prático de aprendizagem por reforço em redes neurais profundas é o uso de redes Q profundas (Deep Q-Networks, DQNs), conforme detalhado por Prince. As DQNs combinam Q-learning com redes neurais profundas para lidar com estados de alta dimensionalidade, como imagens de jogos. O algoritmo DQN treina uma rede neural para aproximar a função de ação-valor $Q(s,a)$ usando uma técnica conhecida como aprendizado por diferença temporal.
No contexto de aprendizagem por reforço, outra abordagem poderosa é o método ator-crítico, que combina componentes de valor e de política. O componente "ator" atualiza a política diretamente enquanto o componente "crítico" estima a função de valor. Este método é detalhado por Murphy e é eficaz para lidar com problemas contínuos e de alta dimensionalidade, em que métodos puramente baseados em valor ou política podem falhar.
A literatura também discute extensivamente os desafios e as melhores práticas na implementação de sistemas de aprendizagem por reforço. Entre eles, a exploração-exploração trade-off é um dos problemas mais críticos. Técnicas como a
PDF exclusivo para Geovana Godoy Viana - rm365544 geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 19 de 23
política epsilon-greedy, em que a política escolhe aleatoriamente uma ação com probabilidade epsilon e a melhor ação conhecida com probabilidade 1-epsilon, são frequentemente utilizadas para balancear a exploração de novas ações e a exploração das ações conhecidas.
Os métodos de aprendizado por reforço profundo são aplicados em uma variedade de domínios, desde jogos, como demonstrado pelo famoso AlphaGo da DeepMind, até robótica e controle automático. A flexibilidade e a capacidade de adaptação desses métodos os tornam uma ferramenta poderosa para resolver problemas complexos em que o ambiente e as recompensas são dinâmicos e parcialmente desconhecidos.
FIAP
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
O QUE VOCÊ VIU NESTA AULA?
Página 20 de 23
Neste encerramento do nosso estudo sobre aprendizagem em redes neurais profundas, consolidamos os conhecimentos adquiridos ao longo das seções. Discutimos a importância de ajustar continuamente os modelos para adaptá-los aos diferentes tipos de aprendizado desde o supervisionado até o por reforço e como essas adaptações impactam diretamente a eficácia das redes em tarefas específicas.
Além disso, exploramos a necessidade crítica de monitorar os drifts de conceito em modelos de aprendizagem contínua para assegurar que alterações nas distribuições dos dados ou nas dinâmicas ambientais não comprometam a performance dos modelos.
Abordamos também a escalabilidade e o desempenho das redes neurais profundas, enfatizando a importância de métricas de qualidade e estratégias para definir limites operacionais que garantam a eficiência e eficácia dos sistemas. A integração contínua e as atualizações sistemáticas dos modelos, essenciais para o desenvolvimento e implementação de novas versões sem interrupções, foram detalhadas para demonstrar como sustentar a relevância e a precisão das soluções em aprendizado profundo em ambientes em constante evolução.
Ao concluir esta aula, você está agora mais preparado(a) para transformar teorias complexas de redes neurais profundas em práticas robustas que impulsionam negócios e satisfazem as necessidades de usuários que evoluem continuamente. A jornada de aprendizado não termina aqui. Encorajamos você a continuar explorando, testando e implementando novas ideias, pois cada passo na produtização é um aprendizado que contribui para desenvolver soluções mais robustas e inovadoras. A prática contínua e a atualização constante dos conhecimentos são, sem dúvida, os pilares para o sucesso na aplicação das redes neurais profundas.
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
REFERÊNCIAS
Página 21 de 23
BISHOP, C. M.; BISHOP, H. Deep Learning: Foundations and Concepts. [s.l.]: Springer, 2024.
GROHS, P.; KUTYNIOK, G. Mathematical Aspects of Deep Learning. [s.l.]: Cambridge University Press, 2023.
HUYEN, C. Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications. [s.l.]: Springer Science+Business Media, LLC, 2007. MURPHY, K. P. Machine Learning: A Probabilistic Perspective. [s.l.]: MIT Press, 2024.
PRINCE, S. J. D. Understanding Deep Learning. [s.l.]: MIT Press, 2024.
STOLL, E. et al. Machine Learning and Systems Engineering. [s.l.]: Springer, 2023.
FIAR
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
Técnicas de Aplicação de Redes Neurais Profundas
Página 22 de 23
PALAVRAS-CHAVE
Redes Neurais. Tipos de Aprendizagem.
FIAP
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com
POS TECH
PDF exclusivo para Geovana Godoy Viana - rm365544
geovana.godoy12@gmail.com